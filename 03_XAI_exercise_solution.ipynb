{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "MLhwxdkDaL_s",
        "xMRlkwexWlFI"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 03\n",
        "\n",
        "In this exercise we look at graphs and post-hoc explanations and want to give you practical experience with dimensionality reduction."
      ],
      "metadata": {
        "id": "ZcKLLA8TMhSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Explanations\n",
        "In the lecture we talked about graphs and how they can be used as scene representations for robot learning tasks. In the exercise, we will have a look at more traditional graph tasks and how we can produce post-hoc explanations from the predictions. We'll use the MUTAG dataset, a collection of graphs representing chemical compounds. The task is to predict whether a compound is mutagenic or not.\n",
        " 1.  Train a simple Graph Convolutional Network (GCN) on the MUTAG dataset for a graph classification task.\n",
        " 2.  Use **GNNExplainer** to find the most influential subgraph and node features for a specific prediction.\n",
        " 3.  Use **PGExplainer** to learn a parameterized explanation for the model's predictions.\n",
        " 4.  Visualize and compare the explanations from both methods.\n",
        "\n",
        "Therefore, we first need to install pytorch-geometric."
      ],
      "metadata": {
        "id": "MLhwxdkDaL_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "id": "inZrREBeaetu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize the first molecule in the dataset to understand its structure. The node colors represent the different types of atoms."
      ],
      "metadata": {
        "id": "AJvQWmUsJgC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, GATv2Conv, global_mean_pool\n",
        "from torch_geometric.explain.algorithm import GNNExplainer, PGExplainer\n",
        "from torch_geometric.explain import Explainer\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "from IPython.display import Image, display\n",
        "\n",
        "dataset = TUDataset(root='/tmp/MUTAG', name='MUTAG')\n",
        "print(f\"Dataset: {dataset.name}\")\n",
        "print(f\"Number of graphs: {len(dataset)}\")\n",
        "print(f\"Number of classes: {dataset.num_classes}\")\n",
        "print(f\"Number of node features: {dataset.num_node_features}\")\n",
        "\n",
        "# Select the first graph\n",
        "graph_to_viz = dataset[0]\n",
        "\n",
        "# Convert to a NetworkX graph for visualization\n",
        "g = to_networkx(graph_to_viz, to_undirected=True)\n",
        "\n",
        "# Get node colors based on atom type\n",
        "node_colors = [graph_to_viz.x[i].argmax().item() for i in range(graph_to_viz.num_nodes)]\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "nx.draw(g, with_labels=True, node_color=node_colors, cmap=\"tab10\", node_size=800)\n",
        "plt.title(\"First Graph in MUTAG Dataset (Molecule)\")\n",
        "plt.show()\n",
        "\n",
        "loader = DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "zaDFJ--k-5Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we define a simple Graph Convolutional Network (GCN) with two convolutional layers followed by a global mean pooling layer and a final linear layer for classification."
      ],
      "metadata": {
        "id": "IO3P-6DO_ggo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(dataset.num_node_features, 64) # You can also try out the GATv2Conv layer\n",
        "        self.conv2 = GCNConv(64, 64)\n",
        "        self.lin = torch.nn.Linear(64, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index, batch=torch.tensor([1])):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "hJhVjVuY_dMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we'll train our GCN model on the MUTAG dataset."
      ],
      "metadata": {
        "id": "EAJgqgzX_rbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GCN().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index, data.batch)\n",
        "        loss = F.nll_loss(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        out = model(data.x, data.edge_index, data.batch)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += int((pred == data.y).sum())\n",
        "    return correct / len(loader.dataset)"
      ],
      "metadata": {
        "id": "yWGwj03g_o4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 201):\n",
        "    train()\n",
        "    if epoch % 10 == 0:\n",
        "        test_acc = test()\n",
        "        print(f'Epoch: {epoch:03d}, Test Accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "id": "hR8hO5Te_vUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GNNExplainer is a model-agnostic explainer that identifies a compact subgraph structure and a small subset of node features that are most influential for a prediction.\n",
        "\n",
        "Visualizing the GNNExplainer Explanation:\n",
        "The highlighted subgraph shows the most important edges for the model's prediction.\n",
        "\n"
      ],
      "metadata": {
        "id": "WDhAu5w6AOZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's pick a single graph to explain\n",
        "data_to_explain = dataset[0].to(device)\n",
        "\n",
        "gnn_explainer = Explainer(\n",
        "    model=model,\n",
        "    algorithm=GNNExplainer(epochs=200, lr=0.01),\n",
        "    explanation_type='model',\n",
        "    node_mask_type='object',\n",
        "    edge_mask_type='object',\n",
        "    model_config=dict(\n",
        "        mode='multiclass_classification',\n",
        "        task_level='graph',\n",
        "        return_type='log_probs',\n",
        "    )\n",
        ")\n",
        "\n",
        "explanation = gnn_explainer(data_to_explain.x, data_to_explain.edge_index)\n",
        "\n",
        "path = 'gnn_explainer_explanation.png'\n",
        "explanation.visualize_graph(path, backend='networkx')\n",
        "display(Image(filename=path))"
      ],
      "metadata": {
        "id": "axqxOmqUALh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pg_explainer = Explainer(\n",
        "    model=model,\n",
        "    algorithm=PGExplainer(epochs=30, lr=0.003),\n",
        "    explanation_type='phenomenon',\n",
        "    edge_mask_type='object',\n",
        "    model_config=dict(\n",
        "        mode='multiclass_classification',\n",
        "        task_level='graph',\n",
        "        return_type='log_probs',\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "# Train the PGExplainer\n",
        "# We need to train the explainer on the training data\n",
        "for epoch in range(30):\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        # PGExplainer needs a target for training, we use the model's prediction\n",
        "        target = model(data.x, data.edge_index, data.batch).argmax(dim=1)\n",
        "        pg_explainer.algorithm.train(epoch, model, data.x, data.edge_index, target=target, batch=data.batch)\n",
        "\n",
        "\n",
        "# Get an explanation for our chosen graph\n",
        "pg_explanation = pg_explainer(data_to_explain.x, data_to_explain.edge_index, target=data_to_explain.y)\n",
        "\n",
        "path = 'pg_explainer_explanation.png'\n",
        "pg_explanation.visualize_graph(path, backend='networkx')\n",
        "display(Image(filename=path))"
      ],
      "metadata": {
        "id": "WAzRrDulHVBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA\n",
        "\n",
        "PCA transforms data accoording to their main axes of variance. To explore the effect of PCA, we use `scikit-learn` to construct a \"Swiss Roll\" Dataset.\n",
        "\n",
        "We can plot the data in 3D and a simple 2D XZ-Plane projection. The Projection highlights the spiral structure of the swiss roll, but looses all information about its width."
      ],
      "metadata": {
        "id": "xMRlkwexWlFI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqv5ZQH9WTCa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dataset\n",
        "data, t = datasets.make_swiss_roll(n_samples=1500, noise=0.05)\n",
        "\n",
        "# 3D Projection\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1,2,1,  projection='3d')\n",
        "ax.scatter(data[:, 0], data[:, 1], data[:, 2],c=t,alpha=0.5)\n",
        "ax.set_title('Swiss Roll 3D')\n",
        "\n",
        "# 2D XZ Projection\n",
        "ax = fig.add_subplot(1,2,2)\n",
        "ax.scatter(data[:, 0], data[:, 2],c=t,alpha=0.5)\n",
        "ax.set_title('Swiss Roll 2D Projection')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QDMnh7gbW1gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We compute the covariance matrix of the dataset and then the covariance matrix' eigenvalue and eigenvectors.\n",
        "\n",
        "You may notice, that the eigenvalues, indicating \"amount of variance\" explained by each eigenvector, is unsorted.\n",
        "\n",
        "For dimensionality reduction, we would sort the vectors by the values and look at the first `n` dimensions only."
      ],
      "metadata": {
        "id": "xAV4X0DbN7qY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data is shape SAMPLES x FEATURES\n",
        "# To get the covariance per Feature, we need the transpose.\n",
        "cov = np.cov(data.T)\n",
        "eig_val, eig_vec = np.linalg.eigh(cov)\n",
        "\n",
        "print(cov)\n",
        "print()\n",
        "print(eig_val)"
      ],
      "metadata": {
        "id": "eARZxfXvXcW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As covered in the lecture, the eigenvectors span a matrix acting as a linear transformation. To transform the original data into the \"PCA Space\", we apply a matrix multiplication.\n",
        "\n",
        "Afterwards we plot the transformed data according to the two axes with the highest eigenvalues.\n",
        "\n",
        "Even though this is a 2D projection as above, due to the PCA transformation it better covers the characteristics of the data."
      ],
      "metadata": {
        "id": "cq5FSLTXOxrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_pca = np.dot(data, eig_vec)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot()\n",
        "\n",
        "# Hardcoded indices 1 and 2. Should try to retrive the index of the highest eigenvalues instead.\n",
        "ax.scatter( data_pca[:, 1], data_pca[:, 2],c=t,alpha=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AGK_VGggxf0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TSNE and UMAP in Praxis\n",
        "\n",
        "While doing our own implementation of tSNE and UMAP would be interesting, we instead want to recommend the following, interactive blockposts. They highlight the effects of the various hyper-parameters.\n",
        "\n",
        "https://distill.pub/2016/misread-tsne/\n",
        "\n",
        "https://pair-code.github.io/understanding-umap/"
      ],
      "metadata": {
        "id": "HjB-LPNNzgPV"
      }
    }
  ]
}