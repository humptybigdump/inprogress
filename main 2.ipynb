{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c758debb-ccf6-44d9-90b9-af6f0aeab348",
   "metadata": {},
   "source": [
    "# MLRS2 - Exercise GAN\n",
    "\n",
    "Please follow this notebook and fill missing parts based no the description in the README.md."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2011a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (only when using Google Colab)\n",
    "!pip install torch torchvision matplotlib tensorboard torchsummary array2gif jupyter tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320a77a4-d19c-40f6-b5f8-e9ba7095f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchsummary import summary\n",
    "from array2gif import write_gif\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24688511-76be-48d6-81eb-3b8f1e8895be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_batch(batch, name=\"\"):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"{name} images\")\n",
    "    plt.imshow(np.transpose(vutils.make_grid(batch.to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Function to convert a tensor to an image plot\n",
    "def tensor_to_plot_image(tensor):\n",
    "    tensor = tensor.cpu().numpy()\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    ax.plot(tensor)\n",
    "    \n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    image = Image.open(buf)\n",
    "    image = np.array(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771df61d-ee2b-4986-9f9b-d646b5aa70f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 0.0002\n",
    "momentum = 0.5\n",
    "z_dim = 100\n",
    "image_size = (28, 28)\n",
    "n_conv = 64\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "os.makedirs(\"./ckpts\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8839864b-12b6-4aaa-a608-be6145990837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MNIST dataset\n",
    "mnist_dataset = MNIST('./data', train=True, download=True, transform=ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(mnist_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28659a22-0689-4bdc-b973-0b1579ef1dd9",
   "metadata": {},
   "source": [
    "### Building the Discriminator\n",
    "\n",
    "Now, let's define the **discriminator** model. It acts as a binary classifier to distinguish real MNIST digits from the fake ones generated by the generator. Pay attention to the use of convolutional layers, `LeakyReLU`, and the final sigmoid activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65c588a-99d3-483f-a4e0-208dd904da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_conv):\n",
    "        super(Discriminator, self).__init__()\n",
    "        ################## TODO ##################\n",
    "        # Disciminator layers:                   #\n",
    "        #    - 3 conv layers with 64 filters, a  #\n",
    "        #      kernelsize of 3 and a stride of 2 #\n",
    "        #      and a padding of 1                # \n",
    "        #    - The last conv layer has 1 output  #\n",
    "        #      channel                           #\n",
    "        #    - 1 conv layer with 1 input and 1   #\n",
    "        #      output channel, a kernelsize of 3 #\n",
    "        #      and a padding of 0.               #\n",
    "        ##########################################\n",
    "        \n",
    "    # forward method\n",
    "    def forward(self, x):\n",
    "        ################## TODO ##################\n",
    "        # Discriminator forward pass:            #\n",
    "        #     - Call the layers from the con-    #\n",
    "        #       structor                         #\n",
    "        #     - Leaky ReLU activations           #\n",
    "        #     - After the 4. conv layer: expand  #\n",
    "        #       dimensions from [N, F] to        #\n",
    "        #       [N, F, 1, 1]                     #\n",
    "        #     - Sigmoid output activation        #\n",
    "        ##########################################\n",
    "        return x\n",
    "\n",
    "    def save_checkpoint(self, optimizer, filepath):\n",
    "        checkpoint = {\n",
    "            'model_state_dict': self.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, filepath)\n",
    "        #print(f\"Discriminator checkpoint saved to {filepath}\")        \n",
    "\n",
    "    def load_checkpoint(self, optimizer, filepath):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        self.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "        #print(f\"Discriminator checkpoint loaded from {filepath}\")\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f54f1-9772-4bd0-bcd3-6a42c7637f9c",
   "metadata": {},
   "source": [
    "### Building the Generator\n",
    "\n",
    "Next, we'll design the **generator** model. This model transforms a latent vector (sampled from a Gaussian distribution) into a 28Ã—28 grayscale image. We'll use transposed convolutions to upscale the feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f739c302-e960-4203-9c84-f726e5f451ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, n_conv):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.n_conv = n_conv\n",
    "        ################## TODO ##################\n",
    "        # Generator layers:                      #\n",
    "        #    - A fully connected layer with z_dim#\n",
    "        #      input nodes and feature_map_size_x#\n",
    "        #      feature_map_size_y *              #\n",
    "        #      feature_map_size_z * n_conv output#\n",
    "        #      nodes                             #\n",
    "        #    - 3 transposed conv layers with 64  #\n",
    "        #      filters, a kernelsize of 3 and a  #\n",
    "        #      stride of 2, and a padding of 1.  # \n",
    "        #    - The last conv layer has 1 output  #\n",
    "        #      channel                           #\n",
    "        #    - The number of feature maps is     #\n",
    "        #      doubled in each subsequent layer  #\n",
    "        #    - 1 conv layer with 1 input and 1   #\n",
    "        #      output channel, a kernelsize of 3 #\n",
    "        #      and a padding of 0.               #\n",
    "        ##########################################\n",
    "        \n",
    "    def forward(self, x):\n",
    "            def forward(self, x):\n",
    "        ################## TODO ######################\n",
    "        # Discriminator forward pass:                #\n",
    "        #     - Call the layers from the con-        #\n",
    "        #       structor                             #\n",
    "        #     - Leaky ReLU activations               #\n",
    "        #     - Use the fully connected layer to     #\n",
    "        #       have the correct amount of neuros    #\n",
    "        #     - Reshape the output of the first      #\n",
    "        #       fully connected layer to             #\n",
    "        #       [-1, n_conv * feature_mapsize_x,     #\n",
    "        #       feature_mapsize_y, feature_mapsize_z]#\n",
    "        #     - Call the layers from the con-        #\n",
    "        #       structor                             #\n",
    "        #     - Leaky ReLU activations               #\n",
    "        #     - Sigmoid output activation            #                \n",
    "        ##############################################\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def save_checkpoint(self, optimizer, filepath):\n",
    "        checkpoint = {\n",
    "            'model_state_dict': self.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, filepath)\n",
    "        \n",
    "        #print(f\"Generator checkpoint saved to {filepath}\")        \n",
    "\n",
    "    def load_checkpoint(self, optimizer, filepath):\n",
    "        checkpoint = torch.load(filepath)\n",
    "        self.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "        #print(f\"Generator checkpoint loaded from {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75deff0f-0169-4509-87ba-a091534c0b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize D and G\n",
    "D = Discriminator(n_conv=n_conv).to(device)\n",
    "G = Generator(z_dim=z_dim, n_conv=n_conv).to(device)\n",
    "\n",
    "summary(D, input_size=(1, 28, 28))\n",
    "summary(G, input_size=(1, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1842fa48-b95e-4356-821b-cf5e55132530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare some data samples and create fake images\n",
    "x_real = next(iter(train_loader))[0]\n",
    "z_noise = torch.randn(batch_size, z_dim, device=device)\n",
    "\n",
    "Dout = D(x_real.to(device))\n",
    "x_fake = G(z_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f96726b-46e1-470a-852c-b3070cb850e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show real images\n",
    "show_image_batch((1 - x_real), name=\"real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1354544-5e7a-48da-808d-6f9a6ec91fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform 1D plots to images\n",
    "plot_images = [tensor_to_plot_image(z_noise[i]) for i in range(len(z_noise))]\n",
    "plot_images = torch.tensor(plot_images, dtype=torch.float32)[..., :-1]\n",
    "plot_images /= 255.\n",
    "plot_images = torch.permute(plot_images, (0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b62c8a-3aec-40c2-8303-b83dc322370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show latent vector and corresponding generated fake image from the generator\n",
    "show_image_batch(plot_images, name=\"z\")\n",
    "show_image_batch(x_fake, name=\"fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110b0a5c-8477-4b82-bfc1-dd4718874dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir ./runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94044742-9f9b-45dd-a63c-8abbd7e70db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Loss and Adam optimizers for both G and D\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizerD = optim.Adam(D.parameters(), lr=learning_rate, betas=(momentum, 0.999))\n",
    "optimizerG = optim.Adam(G.parameters(), lr=learning_rate, betas=(momentum, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59748daf-0ccf-4b96-acac-2e8b88f53486",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "img_list = []\n",
    "total_iters = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aacd813-1c81-477c-a14e-e5ec0f50a520",
   "metadata": {},
   "source": [
    "### Adversarial Training Loop\n",
    "\n",
    "Time to bring both networks together! Implement the mini-max training loop where the discriminator and generator train in an adversarial fashion. Follow the three-step process: \n",
    "1. Train discriminator on real data\n",
    "2. Train discriminator on fake data\n",
    "3. Train generator to fool the discriminator\n",
    "\n",
    "Make sure to monitor losses for both networks during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e52e51e-d05b-47a2-a746-2ac780c05c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    loop = tqdm(enumerate(train_loader, 0), total=len(train_loader), desc=f\"Epoch {epoch+1}/{n_epochs}\", leave=False)\n",
    "    for i, data in loop:\n",
    "        ######################### TODO #########################\n",
    "        # (1) Update the discriminator with real data          #\n",
    "        #     - Zero D's gradients                             #\n",
    "        #     - Create real labels (1): create a tensor holding#\n",
    "        #       the true labels [1, 1, 1, ..., 1]              #\n",
    "        #     - D's forward pass                               #\n",
    "        #     - calculate loss using D's output and real labels#\n",
    "        #     - Backward pass for D  for real labels           #\n",
    "        ########################################################\n",
    "\n",
    "        ######################### TODO #########################\n",
    "        # (2) Update the discriminator with fake data          #\n",
    "        #     - Generate batch of latent vectors               #\n",
    "        #     - Generate fake image based on latent vector     #\n",
    "        #     - Classify all fake image with D                 #\n",
    "        #     - Calculate D's loss on the all-fake batch using #\n",
    "        #       fake labels ([0, 0, 0, ..., 0])                #\n",
    "        #     - Calculate G's loss using outputs and fake      #\n",
    "        #       labels                                         #\n",
    "        #     - Backward pass for G's loss                     #\n",
    "        #     - Add D's and G's losses                         #\n",
    "        #     - Backward pass for D  for fake labels           #\n",
    "        #     - D optimizer step                               #\n",
    "        ########################################################\n",
    "\n",
    "        ######################### TODO #########################\n",
    "        # (3) Update the generator with fake data              #\n",
    "        #     - Zero G's gradients                             #\n",
    "        #     - Perform another forward pass of all-fake batch #\n",
    "        #       through D                                      #\n",
    "        #     - Create  fake labels are real for generator cost#\n",
    "        #       [1, 1, 1, ..., 1]                              #\n",
    "        #     - calculate G's loss                             #\n",
    "        #     - Backward pass for G' loss                      #\n",
    "        #     - G optimizer step                               #\n",
    "        ########################################################\n",
    "\n",
    "        \n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            \n",
    "            writer.add_scalar(\"Losses/G_loss\", loss_G.item(), total_iters)\n",
    "            writer.add_scalar(\"Losses/D_loss\", loss_D.item(), total_iters)\n",
    "\n",
    "        loop.set_postfix({\n",
    "            'Loss_D': f'{loss_D.item():.4f}',\n",
    "            'Loss_G': f'{loss_G.item():.4f}',\n",
    "            'D(x)': f'{D_x:.4f}',\n",
    "            'D(G(z))': f'{D_G_z1:.4f}/{D_G_z2:.4f}'\n",
    "        })\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (total_iters % 50 == 0) or ((epoch == n_epochs-1) and (i == len(train_loader)-1)):\n",
    "            with torch.no_grad():\n",
    "                x_fake = G(z_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(x_fake, padding=2, normalize=True))\n",
    "        \n",
    "        total_iters += 1\n",
    "    D.save_checkpoint(optimizerD, \"./ckpts/discriminator.ckpt\")\n",
    "    G.save_checkpoint(optimizerG, \"./ckpts/generator.ckpt\")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Training time (sec): \", elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2c0db2-7bc4-4162-bb49-cb6099522a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.load_checkpoint(optimizerD, \"./ckpts/discriminator.ckpt\")\n",
    "G.load_checkpoint(optimizerG, \"./ckpts/generator.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61326e51-e129-4901-aab4-25b306735057",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x_fake = G(z_noise).detach().cpu()\n",
    "\n",
    "show_image_batch((1. - x_fake), name=\"fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c5d3f9-cac2-4ec4-9c20-e39f06f9fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and safe GIF from generated images from G\n",
    "img_list_arr = np.array(img_list)\n",
    "img_list_arr = (1. - img_list_arr)\n",
    "img_list_arr *= 255\n",
    "img_list_arr = img_list_arr.astype(np.uint8)\n",
    "\n",
    "write_gif(img_list_arr, 'imgs_G.gif', fps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da02321d-14ac-4922-9397-35c494bfd627",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Great job completing the exercise notebook! The resulting GIF shows how the generator learns over time how to generate number images: [imgs_G.gif](imgs_G.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a76611-a502-4a49-9452-b36adac91ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  1.0011022090911865\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "time.sleep(1)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Training time: \", elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e99584-7462-4820-9314-ca5343ab6276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
