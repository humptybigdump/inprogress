{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aad98b-b9e9-40a9-a011-c347904a2c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "import tensorboard\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# for model evaluation\n",
    "import numpy as np\n",
    "\n",
    "from models.vgg import VGG\n",
    "        \n",
    "from utils import load_cifar10, visualize_cifar10, plot_confusion_matrix\n",
    "\n",
    "\n",
    "seed = 420\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0832bb10-0451-4766-ab7b-b65ee04e1ef8",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# hyperparameters for training\n",
    "batch_size = 32\n",
    "num_epochs = 30\n",
    "lr = 1e-3\n",
    "weight_decay = 15e-5\n",
    "grad_clip = 0.001\n",
    "\n",
    "data_mean, data_std = [0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "# CIFAR-10 Classes\n",
    "class_names = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f91b0aa",
   "metadata": {},
   "source": [
    "# Training and visualization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dd00e6-da46-4d02-ba42-8005a92a7604",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = load_cifar10(root_dir='data', batch_size=batch_size, num_workers=num_workers, augment_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55fa7ca-9064-42ae-94ea-f4bef8cfbe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_cifar10(train_loader, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a7ed6",
   "metadata": {},
   "source": [
    "# 1.1 ResNet Image Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4926ea33",
   "metadata": {},
   "source": [
    "\n",
    "## a) Basic Block Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53be8eae",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![BasicBlock.png](BasicBlock.png \"Basic Block\")\n",
    "\n",
    "<mark>*TODO*: Initialize the layers of the basic block.</mark> \n",
    " \n",
    "The basic block consists of two parts:\n",
    "    \n",
    "1. **Residual layer:**                             \n",
    "    * The residual layer comprises **2 convolutions** using **3x3 kernel** and **padding of 1**. \n",
    "    * The first conv layer uses **'stride'** as stride and the second one a **stride of 1**.   \n",
    "    * After each convolution we need a **batch norm layer**.\n",
    "    * After the first convolution we have **ReLU activation**.\n",
    "    * After the second convolution we have **no activation**.         \n",
    "2. **Residual connection:**                         \n",
    "    * The residual connection is a **skip connection** that combines the **input of the block** with the **output of the last conv layer**.           \n",
    "    * If the **input and output channels are not the same** or the **stride is not one**, we need to use a **1x1 conv layer** with a **stride of 'stride'** and a **batch norm layer** to downsample the input (this is already implemented for you below).   \n",
    "    \n",
    "* (You can set **bias=False** for all conv layers.) \n",
    "\n",
    "<mark>*TODO*: Implement the **forward model** that passes the input through the complete network.</mark> \n",
    "Don't forget to **activate the output of the residual connection**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00080cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        # TODO: Initialize the layers of the basic block.\n",
    "\n",
    "        # Residual connection\n",
    "        self.residual = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #################################################\n",
    "        # TODO: Implement the forward pass of the basic #\n",
    "        # ResNet block. Use 'cbr' order, where 'c' is   #\n",
    "        # conv, 'b' is batchnorm, and 'r' is relu.      #\n",
    "        # Activate the output AFTER adding the residual.#\n",
    "        #################################################\n",
    "        \n",
    "        #################################################\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7c840f",
   "metadata": {},
   "source": [
    "# b) ResNet Implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415e6140",
   "metadata": {},
   "source": [
    "![BasicBlock.png](ResNet.png \"Basic Block\")\n",
    "\n",
    "<mark>*TODO*: Initialize the layers of the ResNet model.</mark> \n",
    "1. **Input layer:**                                  \n",
    "    * Consists of a **conv-batchnorm-relu** block.  \n",
    "    * The conv layer uses **3x3 kernel**, **padding of 1** and a **stride of 1**.        \n",
    "    * Not for all implementations a 3x3 kernel is used, e.g., the original implementation uses a 7x7 kernel followed by max pooling.  \n",
    "        If you want to, you can also try out different kernel sizes and combinations.          \n",
    "2. **ResNet layers:**                               \n",
    "    * Make **4 layers** with the number of blocks as specified by **'num_blocks'**.  \n",
    "      For this, you can use the function `_make_layer`, which makes a block of the class specified in the parameter `block`. For this, we later pass the parameter `block=BasicBlock` to use the Basic block you already implemented.  \n",
    "    * After the **4 layers**, use **Adaptive average pooling** with a **1x1 kernel**.                \n",
    "    * Initialize a **linear layer** to map from channels to **num_classes**.  \n",
    "\n",
    "<mark>*TODO*: Implement the **forward model** that passes the input through the complete network.</mark> \n",
    " \n",
    " Be aware that the linear layer requires a 1D input, while the convolutional layer returns a 2D output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93465359",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        # TODO: Initialize the layers of the ResNet model \n",
    "\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride=s))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #################################################\n",
    "        # TODO: Implement the forward pass of ResNet.   #\n",
    "        # Use 'cbr' order, where 'c' is conv, 'b' is    #\n",
    "        # batchnorm, and 'r' is relu.                   #\n",
    "        # Resize the output after the average pooling   #\n",
    "        # layer to 1D tensor before applying the linear #\n",
    "        # layer.                                        #\n",
    "        #################################################\n",
    "        \n",
    "        #################################################\n",
    "        return x\n",
    "\n",
    "    def save_checkpoint(self, epoch, accuracy, ckptpath=\"checkpoint\"):\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.state_dict(),\n",
    "            'accuracy': accuracy,\n",
    "        }\n",
    "        ckptpath = os.path.join(ckptpath, \"checkpoint_{}_{:.4f}.pth\".format(epoch, accuracy))\n",
    "        # Save the dictionary to file\n",
    "        torch.save(checkpoint, ckptpath)\n",
    "\n",
    "    def load_checkpoint(self, ckptpath, map_location=None):\n",
    "        # Load the saved file\n",
    "        checkpoint = torch.load(ckptpath, map_location=map_location)\n",
    "        \n",
    "        # Restore model and optimizer state\n",
    "        self.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4fca32",
   "metadata": {},
   "source": [
    "# c) Training and Validation\n",
    "\n",
    "Now that you have implemented the model we can train it for image classification on the provided data set.\n",
    "Implement the training and validation loop at the specified positions. You can use the provided comments as guidance.\n",
    "\n",
    "<mark>*TODO*: Implement the training and validation loops.</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f744da9-2d32-41d6-bd5f-6da62d94ee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, scheduler, criterion, device):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in (pbar := tqdm(enumerate(dataloader), total=len(dataloader), ncols=800, unit='batches', leave=False)):\n",
    "        \n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        #################################################\n",
    "        # TODO: Implement the training loop.            #\n",
    "        # 1) Forward pass:                              #\n",
    "        #      - Calculate the model prediction using   #\n",
    "        #        the input data                         #\n",
    "        #      - Calculate the loss using the predic-   #\n",
    "        #        tions and true targets                 #\n",
    "        # 2) Backward pass:                             #\n",
    "        #      - Ensure zero gradients                  #\n",
    "        #      - Perform backward pass to calculate gra-#\n",
    "        #        dients                                 #\n",
    "        #      - Update weights                         #\n",
    "        # 3) Track loss and number of correctly classi- #\n",
    "        #    fied samples                               #\n",
    "        #      - Add loss to total_loss                 #\n",
    "        #      - Calculate predicted class labels       #\n",
    "        #      - Add targets.size to total and the num- #\n",
    "        #        of correctly classified samples to     #\n",
    "        #        correct                                #\n",
    "        #################################################\n",
    "\n",
    "        #################################################\n",
    "       \n",
    "        pbar.set_description(f\"Iteration: {batch_idx}\")\n",
    "        pbar.set_postfix_str(f\"Train Loss: {loss.item():.4f} | Train Acc: {100* correct / total:.2f} | LR: {optimizer.param_groups[0]['lr']}\")        \n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = 100. * correct / total\n",
    "\n",
    "    \n",
    "    if scheduler:\n",
    "        scheduler.step(avg_loss)\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for batch_idx, (inputs, targets) in (pbar := tqdm(enumerate(dataloader), total=len(dataloader), ncols=800, unit='batches', leave=False)):\n",
    "            \n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            #################################################\n",
    "            # TODO: Implement the validation loop.          #\n",
    "            # 1) Forward pass:                              #\n",
    "            #      - Calculate the model prediction using   #\n",
    "            #        the input data                         #\n",
    "            #      - Calculate the loss using the predic-   #\n",
    "            #        tions and true targets                 #\n",
    "            # 2) Track loss and number of correctly classi- #\n",
    "            #    fied samples                               #\n",
    "            #      - Add loss to total_loss                 #\n",
    "            #      - Calculate predicted class labels       #\n",
    "            #      - Add targets.size to total and the num- #\n",
    "            #        of correctly classified samples to     #\n",
    "            #        correct                                #\n",
    "            #################################################\n",
    "        \n",
    "            #################################################\n",
    "            pbar.set_description(f\"Iteration: {batch_idx}\")\n",
    "            pbar.set_postfix_str(f\"Valid Loss: {loss.item():.4f} | Valid Acc: {100* correct / total:.2f}\")\n",
    "            \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = 100. * correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908fd9c1-7bb4-475e-8d1d-9df5919b2b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tensorboard to visualize the training process\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1a67be-9cfd-4d81-a1e1-fe751afcb010",
   "metadata": {},
   "source": [
    "<mark>*TODO*: Train the preimlemented VGG model.</mark>\n",
    "\n",
    "For this you do not need to implement anything. Just run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31332244-08e6-43e8-b842-a28fbfc487fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model architecture\n",
    "vgg = VGG(3, 10)\n",
    "# Loss function, optimizer, and scheduler\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(vgg.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', verbose=False, factor=0.3, patience=3, threshold=0.09)\n",
    "\n",
    "summary(vgg, (3, 32, 32), batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48ca8af-04fc-4b6c-91ab-588a7e244905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writer will output to ./runs/ directory by default\n",
    "writer = SummaryWriter()\n",
    "ckptpath = os.path.join(writer.log_dir, \"checkpoints\")\n",
    "\n",
    "# Metric to watch\n",
    "best_valid_acc = 0.0\n",
    "\n",
    "# Training loop\n",
    "for epoch in (pbar := tqdm(range(num_epochs), unit='epoch')):\n",
    "    pbar.set_description(f\"Epoch {epoch + 1}\")\n",
    "\n",
    "    train_loss, train_acc = train(vgg, train_loader, optimizer, scheduler, loss_function, device)\n",
    "    valid_loss, valid_acc = validate(vgg, val_loader, loss_function, device)\n",
    "\n",
    "    writer.add_scalars('losses', {'train': train_loss, 'valid': valid_loss}, global_step=epoch)\n",
    "    writer.add_scalars('accuracies', {'train': train_acc, 'valid': valid_acc}, global_step=epoch)\n",
    "    pbar.set_postfix_str(f\"Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.2f}\")\n",
    "\n",
    "\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        vgg.save_checkpoint(epoch, accuracy=valid_acc, ckptpath=ckptpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e72ceef",
   "metadata": {},
   "source": [
    "<mark>*TODO*: Train your ResNet model.</mark>\n",
    "\n",
    "For this you do not need to implement anything. Just run the code below. However, you are encouraged to look through the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6bbff1-f978-4eb5-9c37-5fe9a08d9fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model architecture\n",
    "resnet = ResNet(BasicBlock, num_blocks=[1, 2, 2, 1], num_classes=10)\n",
    "# Loss function, optimizer, and scheduler\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', verbose=True, factor=0.3, patience=3, threshold=0.09)\n",
    "\n",
    "summary(resnet, (3, 32, 32), batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2e01b2-8511-4949-925d-49e46e3503ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writer will output to ./runs/ directory by default\n",
    "writer = SummaryWriter()\n",
    "ckptpath = os.path.join(writer.log_dir, \"checkpoints\")\n",
    "\n",
    "# Metric to watch\n",
    "best_valid_acc = 0.0\n",
    "\n",
    "# Training loop\n",
    "for epoch in (pbar := tqdm(range(num_epochs), unit='epoch')):\n",
    "    pbar.set_description(f\"Epoch {epoch + 1}\")\n",
    "\n",
    "    train_loss, train_acc = train(resnet, train_loader, optimizer, scheduler, loss_function, device)\n",
    "    valid_loss, valid_acc = validate(resnet, val_loader, loss_function, device)\n",
    "\n",
    "    writer.add_scalars('losses', {'train': train_loss, 'valid': valid_loss}, global_step=epoch)\n",
    "    writer.add_scalars('accuracies', {'train': train_acc, 'valid': valid_acc}, global_step=epoch)\n",
    "    pbar.set_postfix_str(f\"Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.2f}\")\n",
    "\n",
    "\n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        resnet.save_checkpoint(epoch, accuracy=valid_acc, ckptpath=ckptpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5720a849-e0ae-46d6-a619-61b6e9d9161a",
   "metadata": {},
   "source": [
    "# Evaluation \n",
    "For evaluating both models we load the models from a checkpoint and load the parameters into the model. For comparing both models'\n",
    "performance confusion matrices are used. \n",
    "## Confusion Matrix\n",
    "A confusion matrix is a powerful tool in classification analysis that helps visualize the performance of a classifier. It is a tabular way to illustrate the discrepancies between predicted and actual classes. This tool is particularly useful in supervised learning where the outcomes are already known.A confusion matrix is a powerful tool in classification analysis that helps visualize the performance of a classifier. It is a tabular way to illustrate the discrepancies between predicted and actual classes. This tool is particularly useful in supervised learning where the outcomes are already known.\n",
    "\n",
    "### Structure of a Confusion Matrix\n",
    "For a binary classification problem, the confusion matrix is a $2\\times2$ table consisting of four different components:\n",
    "- True Positives (TP): The number of instances that were predicted as positive and are actually positive.\n",
    "- False Positives (FP): The number of instances that were predicted as positive but are actually negative.\n",
    "- True Negatives (TN): The number of instances that were predicted as negative and are actually negative.\n",
    "- False Negatives (FN): The number of instances that were predicted as negative but are actually positive.\n",
    "\n",
    "|                  | Predicted Positive   | Predicted Negative   |\n",
    "|        ---       |        ---           |         ---          |\n",
    "| Actual Positive  | True Positives (TP)  | False Negatives (FN) |\n",
    "| Actual Negative  | False Positives (FP) | True Negatives (TN)  |\n",
    "\n",
    "### Structure of a Multi-Class Confusion Matrix\n",
    "For a classification problem involving multiple classes (e.g., $10$ classes), the confusion matrix expands from a $2\\times2$ structure to an $n \\times n$ structure, where $n$ is the number of classes. This matrix provides a detailed picture of the classifier's performance across all these classes.\n",
    "Each row of the matrix corresponds to the actual class, while each column corresponds to the predicted class. The diagonal elements of the matrix (from top left to bottom right) represent the number of correct predictions for each class (i.e., the true positives for each class).\n",
    "\n",
    "\n",
    "|   | class $1$   | class $2$  | $\\dots$  | class $10$   |\n",
    "|---|---|---|---|---|\n",
    "| class $1$   | TP $1$  | FP $1, 2$  | $\\dots$   | FP $1, 10$   |\n",
    "| class $2$   | FP $2, 1$  | TP $2$  | $\\dots$   | FP $2, 10$  |\n",
    "| $\\dots$     | $\\dots$  |$\\dots$   | $\\dots$   |$\\dots$   |\n",
    "|  class $10$ | FP $10, 1$  |   | $\\dots$   | TP $10$  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd59e1ba",
   "metadata": {},
   "source": [
    "<mark>*TODO*: change the model paths to your model paths</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af183465-cf13-4e38-951d-08f95a198fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG(3, 10)\n",
    "\n",
    "#################################################\n",
    "# TODO: Change the path to the path of your     #\n",
    "# trained VGG model.                            #\n",
    "#################################################\n",
    "cktp = './runs/Apr24_13-59-53_IFLPC205/checkpoints/checkpoint_47_76.89.pth'\n",
    "vgg.load_checkpoint(cktp, map_location=device)\n",
    "\n",
    "plot_confusion_matrix(vgg, val_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110db405-279c-417c-905e-b6c39e69eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet(BasicBlock, num_blocks=[1, 2, 2, 1], num_classes=10)\n",
    "\n",
    "#################################################\n",
    "# TODO: Change the path to the path of your     #\n",
    "# trained ResNet model.                         #\n",
    "#################################################\n",
    "cktp = \"./runs/Apr24_18-06-53_IFLPC205/checkpoints/checkpoint_51_86.77.pth\"\n",
    "resnet.load_checkpoint(cktp, map_location=device)\n",
    "\n",
    "plot_confusion_matrix(resnet, val_loader, class_names, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2489655-e8f4-4d54-b00d-936e7f444484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
