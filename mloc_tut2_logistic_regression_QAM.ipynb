{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Logistic Regression for QAM Demodulation in AWGN Channels\n",
    "\n",
    "This code is provided as supplementary material of the lecture Machine Learning and Optimization in Communications (MLOC).<br>\n",
    "\n",
    "This code serves as:\n",
    "* an exercise to demodulate QAM symbols using multiclass logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "from ipywidgets import interactive\n",
    "import ipywidgets as widgets\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use a simple AWGN model and normalize the constellations to unit energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "constellations = {'16-QAM': np.array([-3,-3,-3,-3,-1,-1,-1,-1,1,1,1,1,3,3,3,3]) + 1j*np.array([-3,-1,1,3,-3,-1,1,3,-3,-1,1,3,-3,-1,1,3]), \\\n",
    "                  '16-APSK': np.array([1,-1,0,0,1.4,1.4,-1.4,-1.4,3,-3,0,0,5,-5,0,0]) + 1j*np.array([0,0,1,-1,1.4,-1.4,1.4,-1.4,0,0,4,-4,0,0,6,-6]), \\\n",
    "                  '4-test' : np.array([-1,2,0,4]) + 1j*np.array([0,0,3,0])}\n",
    "\n",
    "# permute constellations so that it is visually more appealing with the chosen colormap\n",
    "# also normalize constellation\n",
    "for cname in constellations.keys():\n",
    "    norm_factor = 1 / np.sqrt(np.mean(np.abs(constellations[cname])**2))\n",
    "    constellations[cname] = constellations[cname][np.random.permutation(len(constellations[cname]))] * norm_factor\n",
    "    \n",
    "\n",
    "constellation = constellations['16-QAM']\n",
    "n = len(constellation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple AWGN channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_channel(x, SNR):  \n",
    "    # noise variance per step    \n",
    "    sigma = np.sqrt( 0.5 * (10**(-SNR/10.0)) )\n",
    "\n",
    "    return x + sigma*(np.random.randn(len(x)) + 1j*np.random.randn(len(x)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 10000\n",
    "\n",
    "def plot_constellation(SNR):\n",
    "    ti = np.random.randint(len(constellation),size=length)\n",
    "    t = constellation[ti]\n",
    "    r = simulate_channel(t, SNR)\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    font = {'size'   : 14}\n",
    "    plt.rc('font', **font)\n",
    "    plt.rc('text', usetex=True)\n",
    "    plt.scatter(np.real(r), np.imag(r), c=ti, cmap='tab20')\n",
    "    plt.xlabel(r'$\\Re\\{r\\}$',fontsize=14)\n",
    "    plt.ylabel(r'$\\Im\\{r\\}$',fontsize=14)\n",
    "    plt.axis('equal')\n",
    "    plt.title('Received constellation (SNR = $%1.2f$\\,dBm)' % (SNR))    \n",
    "    \n",
    "interactive_update = interactive(plot_constellation, SNR = widgets.FloatSlider(min=0.0,max=30.0,step=0.1,value=15, continuous_update=False, description='SNR (dB)', style={'description_width': 'initial'}, layout=widgets.Layout(width='50%')))\n",
    "\n",
    "\n",
    "output = interactive_update.children[-1]\n",
    "output.layout.height = '500px'\n",
    "interactive_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for plotting the constellations and the decision region of the different constellations and classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dec(t, r, weights, title):\n",
    "    ext_x = max(abs(np.real(r)))\n",
    "    ext_y = max(abs(np.imag(r)))\n",
    "    ext_max = max(ext_x,ext_y)*1.2\n",
    "\n",
    "    mgx,mgy = np.meshgrid(np.linspace(-ext_max,ext_max,200), np.linspace(-ext_max,ext_max,200))\n",
    "    meshgrid = np.column_stack((np.reshape(mgx,(-1,1)),np.reshape(mgy,(-1,1))))\n",
    "    \n",
    "    decision_region = np.argmax(logistic_prediction(meshgrid, weights), axis=1) / 16    \n",
    "    \n",
    "    plt.figure(figsize=(8,8))    \n",
    "    #plt.scatter(mgx,mgy,c = decision_region,cmap='tab20', s=5, alpha=0.7)\n",
    "    plt.scatter(meshgrid[:,0],meshgrid[:,1],c = decision_region,cmap='tab20', s=5, alpha=0.7)\n",
    "    plt.scatter(np.real(r), np.imag(r), c=ti, cmap='tab20')\n",
    "    \n",
    "    plt.axis('scaled')\n",
    "    plt.xlim((-ext_max,+ext_max))\n",
    "    plt.ylim((-ext_max,+ext_max))\n",
    "    plt.xlabel(r'$\\Re\\{r\\}$',fontsize=16)\n",
    "    plt.ylabel(r'$\\Im\\{r\\}$',fontsize=16)\n",
    "    plt.title(title,fontsize=16)    \n",
    "    \n",
    "def plot_dec_bias(t, r, weights_theta, weights_bias, title):\n",
    "    ext_x = max(abs(np.real(r)))\n",
    "    ext_y = max(abs(np.imag(r)))\n",
    "    ext_max = max(ext_x,ext_y)*1.2\n",
    "\n",
    "    mgx,mgy = np.meshgrid(np.linspace(-ext_max,ext_max,200), np.linspace(-ext_max,ext_max,200))\n",
    "    meshgrid = np.column_stack((np.reshape(mgx,(-1,1)),np.reshape(mgy,(-1,1))))\n",
    "\n",
    "    decision_region = np.argmax(logistic_prediction_bias(meshgrid, weights_theta, weights_bias), axis=1) / 16\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    #plt.contourf(mgx,mgy,decision_region.reshape(mgy.shape),cmap='tab20',vmin=0,vmax=1)\n",
    "    plt.scatter(mgx,mgy,c = decision_region,cmap='tab20', s=5, alpha=0.7)\n",
    "    plt.scatter(np.real(r), np.imag(r), c=ti, cmap='tab20')\n",
    "    \n",
    "    plt.axis('scaled')\n",
    "    plt.xlim((-ext_max,+ext_max))\n",
    "    plt.ylim((-ext_max,+ext_max))\n",
    "    plt.xlabel(r'$\\Re\\{r\\}$',fontsize=16)\n",
    "    plt.ylabel(r'$\\Im\\{r\\}$',fontsize=16)\n",
    "    plt.title(title,fontsize=16)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carry out gradient descent. Please insert the relevant code for yourself.\n",
    "Recall that the softmax function computes probabilities\n",
    "$$\n",
    "p_i = \\frac{\\exp(\\boldsymbol{\\theta}_i^T\\boldsymbol{x})}{\\sum_{k=1}^n\\exp(\\boldsymbol{\\theta}_k^T\\boldsymbol{x})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# sigmoid\n",
    "def softmax(logits):\n",
    "    # insert here the function that generates the softmax output, input are the logits\n",
    "    return 0\n",
    "\n",
    "def logistic_prediction(x, theta):\n",
    "    # carry out the prediction, x are the examples of the training set in shape (N, 2)\n",
    "    #                           theta are the weight vectors in shape (2, n)  [each column is a vector]\n",
    "    return 0\n",
    "\n",
    "def training_loss(x, theta):\n",
    "    # Compute the loss function, x are the examples of the training set in shape (N, 2)\n",
    "    #                           theta are the weight vectors in shapae (2, n)  [each column is a vector]\n",
    "    return 0\n",
    "\n",
    "def training_gradient(x, theta):\n",
    "    # Function that computes the gradient 'by hand', i.e., by carrying out the maths\n",
    "    # Input x are the examples of the training set in shape (N,2)\n",
    "    #       theta are the weight vectors in shapae (2, n)  [each column is a vector]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main program loop, carry out 1000 iterations of gradient descent for finding the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# Build dataset\n",
    "SNR = 19 #dB\n",
    "\n",
    "# Transmit data (bits)\n",
    "ti = np.random.randint(len(constellation),size=length)\n",
    "t = constellation[ti]\n",
    "# Channel output\n",
    "r = simulate_channel(t, SNR)\n",
    "inputs = np.column_stack((np.real(r), np.imag(r)))\n",
    "\n",
    "\n",
    "# random weights to start with\n",
    "np.random.seed(1)\n",
    "n = len(constellation)\n",
    "weights = np.random.randn(2,n)\n",
    "\n",
    "# main gradient descent loop\n",
    "for i in range(1000):            \n",
    "    if i % 100 == 0:\n",
    "        preds = np.argmax(logistic_prediction(inputs, weights), axis=1)\n",
    "        error_rate = np.mean(preds != ti)\n",
    "        print('Step',i,' : ',error_rate,' error_rate with loss ',training_loss(inputs, weights))\n",
    "    weights -= training_gradient(inputs, weights) * 0.01\n",
    "    \n",
    "plot_dec(ti, r, weights, 'After optimization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Logistic Regression with Bias\n",
    "\n",
    "We have seen in the example before that this approach does not work. Now we add a bias value to each logit. In this case, we get the probabilities\n",
    "$$\n",
    "p_i = \\frac{\\exp(\\boldsymbol{\\theta}_i^T\\boldsymbol{x}+c_i)}{\\sum_{k=1}^n\\exp(\\boldsymbol{\\theta}_k^T\\boldsymbol{x}+c_k)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_prediction_bias(x, theta, bias):\n",
    "    # carry out the prediction, x are the examples of the training set in shape (N, 2)\n",
    "    #                           theta are the weight vectors in shape (2, n)  [each column is a vector]\n",
    "    #                           bias is a vector of lengt n carrying the biases\n",
    "    return 0\n",
    "\n",
    "def training_loss_bias(inputs, theta, bias):\n",
    "    # Compute the loss function, x are the examples of the training set in shape (N, 2)\n",
    "    #                           theta are the weight vectors in shape (2, n)  [each column is a vector]\n",
    "    #                           bias is a vector of lengt n carrying the biases\n",
    "    return 0\n",
    "\n",
    "def training_gradient_bias(x, theta, bias):\n",
    "    # Function that computes the gradient 'by hand', i.e., by carrying out the maths\n",
    "    # Input x are the examples of the training set in shape (N,2)\n",
    "    #       theta are the weight vectors in shape (2, n)  [each column is a vector]\n",
    "    #       bias is a vector of lengt n carrying the biases\n",
    "    # Output are a matrix corresponding to the gradients of the weight vector theta and a vector corresponding to the gradient of the bias\n",
    "    return 0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataset\n",
    "SNR = 19 #dB\n",
    "\n",
    "# Transmit data (bits)\n",
    "ti = np.random.randint(len(constellation),size=length)\n",
    "t = constellation[ti]\n",
    "# Channel output\n",
    "r = simulate_channel(t, SNR)\n",
    "inputs = np.column_stack((np.real(r), np.imag(r)))\n",
    "\n",
    "\n",
    "# random weights to start with\n",
    "np.random.seed(1)\n",
    "weights_theta = np.random.randn(2,n)\n",
    "weights_bias = np.random.randn(n)\n",
    "\n",
    "for i in range(1000):            \n",
    "    if i % 100 == 0:\n",
    "        preds = np.argmax(logistic_prediction_bias(inputs, weights_theta, weights_bias), axis=1)\n",
    "        error_rate = np.mean(preds != ti)\n",
    "        print('Step',i,' : ',error_rate,' error_rate with loss ',training_loss_bias(inputs, weights_theta, weights_bias))\n",
    "    grad_w,grad_b = training_gradient_bias(inputs, weights_theta, weights_bias) \n",
    "    weights_theta -= 0.01 * grad_w\n",
    "    weights_bias -= 0.01 * grad_b\n",
    "    \n",
    "plot_dec_bias(ti, r, weights_theta, weights_bias, 'After optimization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
