{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Approximation with a Simple Neural Network\n",
    "\n",
    "This code is provided as supplementary material of the lecture Machine Learning and Optimization in Communications (MLOC).<br>\n",
    "\n",
    "This code illustrates:\n",
    "* Approximation of 1D functions using a simple neural network (NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using the following device for learning: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"We are using the following device for learning:\",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a **neural network** as required by the exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simple_NN, self).__init__()\n",
    "       \n",
    "        # initialize weights\n",
    "        weight_init = np.array([2.0, -10.0, 1.0, -3.0, -4.0, -1.0, 1.0])               \n",
    "        self.weights = torch.nn.Parameter(torch.from_numpy(weight_init))\n",
    "        \n",
    "        # random weights\n",
    "        #self.weights = torch.nn.Parameter(torch.randn(7))\n",
    "        \n",
    "        # Non-linearity via softmax\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.ReLU = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        a1 = self.sigmoid(self.weights[0]*x)\n",
    "        a2 = self.sigmoid(self.weights[1]*x)\n",
    "        a3 = self.ReLU(self.weights[2]*a1 + self.weights[3]*a2)\n",
    "        out = self.sigmoid(self.weights[4]*a1 + self.weights[5]*a2 + self.weights[6]*a3)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute output for the given input values and the given weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0759, 0.0664], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = simple_NN()\n",
    "model.to(device)\n",
    "\n",
    "x = torch.Tensor([0,1])\n",
    "out = model(x)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0  : Loss =  tensor(0.3551, grad_fn=<MseLossBackward>)\n",
      "Iteration 1000  : Loss =  tensor(0.2001, grad_fn=<MseLossBackward>)\n",
      "Iteration 2000  : Loss =  tensor(0.0828, grad_fn=<MseLossBackward>)\n",
      "Iteration 3000  : Loss =  tensor(0.0621, grad_fn=<MseLossBackward>)\n",
      "Iteration 4000  : Loss =  tensor(0.0529, grad_fn=<MseLossBackward>)\n",
      "Iteration 5000  : Loss =  tensor(0.0477, grad_fn=<MseLossBackward>)\n",
      "Iteration 6000  : Loss =  tensor(0.0442, grad_fn=<MseLossBackward>)\n",
      "Iteration 7000  : Loss =  tensor(0.0415, grad_fn=<MseLossBackward>)\n",
      "Iteration 8000  : Loss =  tensor(0.0394, grad_fn=<MseLossBackward>)\n",
      "Iteration 9000  : Loss =  tensor(0.0377, grad_fn=<MseLossBackward>)\n",
      "Iteration 10000  : Loss =  tensor(0.0362, grad_fn=<MseLossBackward>)\n",
      "Iteration 11000  : Loss =  tensor(0.0349, grad_fn=<MseLossBackward>)\n",
      "Iteration 12000  : Loss =  tensor(0.0337, grad_fn=<MseLossBackward>)\n",
      "Iteration 13000  : Loss =  tensor(0.0327, grad_fn=<MseLossBackward>)\n",
      "Iteration 14000  : Loss =  tensor(0.0318, grad_fn=<MseLossBackward>)\n",
      "Iteration 15000  : Loss =  tensor(0.0309, grad_fn=<MseLossBackward>)\n",
      "Iteration 16000  : Loss =  tensor(0.0302, grad_fn=<MseLossBackward>)\n",
      "Iteration 17000  : Loss =  tensor(0.0294, grad_fn=<MseLossBackward>)\n",
      "Iteration 18000  : Loss =  tensor(0.0288, grad_fn=<MseLossBackward>)\n",
      "Iteration 19000  : Loss =  tensor(0.0282, grad_fn=<MseLossBackward>)\n",
      "Iteration 20000  : Loss =  tensor(0.0276, grad_fn=<MseLossBackward>)\n",
      "Iteration 21000  : Loss =  tensor(0.0270, grad_fn=<MseLossBackward>)\n",
      "Iteration 22000  : Loss =  tensor(0.0265, grad_fn=<MseLossBackward>)\n",
      "Iteration 23000  : Loss =  tensor(0.0260, grad_fn=<MseLossBackward>)\n",
      "Iteration 24000  : Loss =  tensor(0.0255, grad_fn=<MseLossBackward>)\n",
      "Iteration 25000  : Loss =  tensor(0.0250, grad_fn=<MseLossBackward>)\n",
      "Iteration 26000  : Loss =  tensor(0.0246, grad_fn=<MseLossBackward>)\n",
      "Iteration 27000  : Loss =  tensor(0.0242, grad_fn=<MseLossBackward>)\n",
      "Iteration 28000  : Loss =  tensor(0.0238, grad_fn=<MseLossBackward>)\n",
      "Iteration 29000  : Loss =  tensor(0.0234, grad_fn=<MseLossBackward>)\n",
      "Iteration 30000  : Loss =  tensor(0.0230, grad_fn=<MseLossBackward>)\n",
      "Iteration 31000  : Loss =  tensor(0.0226, grad_fn=<MseLossBackward>)\n",
      "Iteration 32000  : Loss =  tensor(0.0222, grad_fn=<MseLossBackward>)\n",
      "Iteration 33000  : Loss =  tensor(0.0219, grad_fn=<MseLossBackward>)\n",
      "Iteration 34000  : Loss =  tensor(0.0215, grad_fn=<MseLossBackward>)\n",
      "Iteration 35000  : Loss =  tensor(0.0212, grad_fn=<MseLossBackward>)\n",
      "Iteration 36000  : Loss =  tensor(0.0209, grad_fn=<MseLossBackward>)\n",
      "Iteration 37000  : Loss =  tensor(0.0206, grad_fn=<MseLossBackward>)\n",
      "Iteration 38000  : Loss =  tensor(0.0203, grad_fn=<MseLossBackward>)\n",
      "Iteration 39000  : Loss =  tensor(0.0200, grad_fn=<MseLossBackward>)\n",
      "Iteration 40000  : Loss =  tensor(0.0198, grad_fn=<MseLossBackward>)\n",
      "Iteration 41000  : Loss =  tensor(0.0195, grad_fn=<MseLossBackward>)\n",
      "Iteration 42000  : Loss =  tensor(0.0192, grad_fn=<MseLossBackward>)\n",
      "Iteration 43000  : Loss =  tensor(0.0190, grad_fn=<MseLossBackward>)\n",
      "Iteration 44000  : Loss =  tensor(0.0188, grad_fn=<MseLossBackward>)\n",
      "Iteration 45000  : Loss =  tensor(0.0186, grad_fn=<MseLossBackward>)\n",
      "Iteration 46000  : Loss =  tensor(0.0184, grad_fn=<MseLossBackward>)\n",
      "Iteration 47000  : Loss =  tensor(0.0182, grad_fn=<MseLossBackward>)\n",
      "Iteration 48000  : Loss =  tensor(0.0180, grad_fn=<MseLossBackward>)\n",
      "Iteration 49000  : Loss =  tensor(0.0178, grad_fn=<MseLossBackward>)\n",
      "Iteration 50000  : Loss =  tensor(0.0176, grad_fn=<MseLossBackward>)\n",
      "Iteration 51000  : Loss =  tensor(0.0175, grad_fn=<MseLossBackward>)\n",
      "Iteration 52000  : Loss =  tensor(0.0173, grad_fn=<MseLossBackward>)\n",
      "Iteration 53000  : Loss =  tensor(0.0172, grad_fn=<MseLossBackward>)\n",
      "Iteration 54000  : Loss =  tensor(0.0170, grad_fn=<MseLossBackward>)\n",
      "Iteration 55000  : Loss =  tensor(0.0169, grad_fn=<MseLossBackward>)\n",
      "Iteration 56000  : Loss =  tensor(0.0168, grad_fn=<MseLossBackward>)\n",
      "Iteration 57000  : Loss =  tensor(0.0167, grad_fn=<MseLossBackward>)\n",
      "Iteration 58000  : Loss =  tensor(0.0166, grad_fn=<MseLossBackward>)\n",
      "Iteration 59000  : Loss =  tensor(0.0165, grad_fn=<MseLossBackward>)\n",
      "Iteration 60000  : Loss =  tensor(0.0164, grad_fn=<MseLossBackward>)\n",
      "Iteration 61000  : Loss =  tensor(0.0163, grad_fn=<MseLossBackward>)\n",
      "Iteration 62000  : Loss =  tensor(0.0162, grad_fn=<MseLossBackward>)\n",
      "Iteration 63000  : Loss =  tensor(0.0161, grad_fn=<MseLossBackward>)\n",
      "Iteration 64000  : Loss =  tensor(0.0160, grad_fn=<MseLossBackward>)\n",
      "Iteration 65000  : Loss =  tensor(0.0159, grad_fn=<MseLossBackward>)\n",
      "Iteration 66000  : Loss =  tensor(0.0158, grad_fn=<MseLossBackward>)\n",
      "Iteration 67000  : Loss =  tensor(0.0158, grad_fn=<MseLossBackward>)\n",
      "Iteration 68000  : Loss =  tensor(0.0157, grad_fn=<MseLossBackward>)\n",
      "Iteration 69000  : Loss =  tensor(0.0156, grad_fn=<MseLossBackward>)\n",
      "Iteration 70000  : Loss =  tensor(0.0156, grad_fn=<MseLossBackward>)\n",
      "Iteration 71000  : Loss =  tensor(0.0155, grad_fn=<MseLossBackward>)\n",
      "Iteration 72000  : Loss =  tensor(0.0154, grad_fn=<MseLossBackward>)\n",
      "Iteration 73000  : Loss =  tensor(0.0154, grad_fn=<MseLossBackward>)\n",
      "Iteration 74000  : Loss =  tensor(0.0153, grad_fn=<MseLossBackward>)\n",
      "Iteration 75000  : Loss =  tensor(0.0152, grad_fn=<MseLossBackward>)\n",
      "Iteration 76000  : Loss =  tensor(0.0152, grad_fn=<MseLossBackward>)\n",
      "Iteration 77000  : Loss =  tensor(0.0151, grad_fn=<MseLossBackward>)\n",
      "Iteration 78000  : Loss =  tensor(0.0150, grad_fn=<MseLossBackward>)\n",
      "Iteration 79000  : Loss =  tensor(0.0150, grad_fn=<MseLossBackward>)\n",
      "Iteration 80000  : Loss =  tensor(0.0149, grad_fn=<MseLossBackward>)\n",
      "Iteration 81000  : Loss =  tensor(0.0148, grad_fn=<MseLossBackward>)\n",
      "Iteration 82000  : Loss =  tensor(0.0147, grad_fn=<MseLossBackward>)\n",
      "Iteration 83000  : Loss =  tensor(0.0147, grad_fn=<MseLossBackward>)\n",
      "Iteration 84000  : Loss =  tensor(0.0146, grad_fn=<MseLossBackward>)\n",
      "Iteration 85000  : Loss =  tensor(0.0145, grad_fn=<MseLossBackward>)\n",
      "Iteration 86000  : Loss =  tensor(0.0144, grad_fn=<MseLossBackward>)\n",
      "Iteration 87000  : Loss =  tensor(0.0143, grad_fn=<MseLossBackward>)\n",
      "Iteration 88000  : Loss =  tensor(0.0142, grad_fn=<MseLossBackward>)\n",
      "Iteration 89000  : Loss =  tensor(0.0142, grad_fn=<MseLossBackward>)\n",
      "Iteration 90000  : Loss =  tensor(0.0141, grad_fn=<MseLossBackward>)\n",
      "Iteration 91000  : Loss =  tensor(0.0140, grad_fn=<MseLossBackward>)\n",
      "Iteration 92000  : Loss =  tensor(0.0139, grad_fn=<MseLossBackward>)\n",
      "Iteration 93000  : Loss =  tensor(0.0138, grad_fn=<MseLossBackward>)\n",
      "Iteration 94000  : Loss =  tensor(0.0137, grad_fn=<MseLossBackward>)\n",
      "Iteration 95000  : Loss =  tensor(0.0136, grad_fn=<MseLossBackward>)\n",
      "Iteration 96000  : Loss =  tensor(0.0135, grad_fn=<MseLossBackward>)\n",
      "Iteration 97000  : Loss =  tensor(0.0134, grad_fn=<MseLossBackward>)\n",
      "Iteration 98000  : Loss =  tensor(0.0133, grad_fn=<MseLossBackward>)\n",
      "Iteration 99000  : Loss =  tensor(0.0132, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# initialize model\n",
    "model = simple_NN()\n",
    "model.to(device)\n",
    "\n",
    "# TODO select loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# TODO select Adam optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)  \n",
    "#optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Build dataset\n",
    "x_train = torch.Tensor([-3.0, -2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0, 3.0])\n",
    "y_train = torch.Tensor([0.7312, 0.7339, 0.7438, 0.7832, 0.8903, 0.9820, 0.8114, 0.5937, 0.5219, 0.5049, 0.5002])\n",
    "\n",
    "\n",
    "# main gradient descent loop\n",
    "for i in range(100000):       \n",
    "    x_hat = model(x_train)\n",
    "    loss = loss_fn(x_hat, y_train)\n",
    "    \n",
    "    # compute gradient\n",
    "    loss.backward()\n",
    "    \n",
    "    # optimize\n",
    "    optimizer.step()\n",
    "    \n",
    "    # reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print('Iteration',i,' : Loss = ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([  2.6254, -10.0122,   0.7824,  -2.9615,   0.8522,   1.3668,  -0.6186],\n",
      "       dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7969, 0.7976, 0.7995, 0.8060, 0.8232, 0.7520, 0.5772, 0.5850, 0.5893,\n",
      "        0.5906, 0.5910], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(x_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(1, figsize=(8,6))\n",
    "\n",
    "x_eval = np.linspace(-5,5,100)\n",
    "x_hat = model(torch.from_numpy(x_eval))\n",
    "\n",
    "plt.plot(x_eval, x_hat.detach().cpu().numpy(), '-', color='darkorange', linewidth=1.0)   \n",
    "plt.plot(x_train, y_train, '.', color='royalblue')\n",
    "plt.legend(['NN output', 'Training Data'])\n",
    "plt.grid(which='both');\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.xlabel('x');\n",
    "plt.ylabel('y')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
